{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-17T17:13:54.874335Z",
     "start_time": "2023-07-17T17:13:52.650351200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eclip\\GitHub\\panda-gym\\venv\\Lib\\site-packages\\gymnasium-0.28.1-py3.11.egg\\gymnasium\\envs\\registration.py:693: UserWarning: \u001B[33mWARN: Overriding environment PandaReachAO-v3 already in registry.\u001B[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import evaluate\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import gymnasium\n",
    "from run.train import configuration\n",
    "import json\n",
    "from copy import copy, deepcopy\n",
    "import panda_gym\n",
    "import pybullet\n",
    "from sb3_contrib import TQC\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# standard settings\n",
    "human=False\n",
    "reward_type=\"kumar_her\"\n",
    "n_substeps=20\n",
    "max_ep_steps = 200\n",
    "goal_condition=\"reach\"\n",
    "#register envs\n",
    "panda_gym.register_reach_ao(max_ep_steps)\n",
    "\n",
    "# visual stuff\n",
    "sphere_list = []\n",
    "sphere_count = 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-17T17:13:54.878250300Z",
     "start_time": "2023-07-17T17:13:54.876342600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# narrow_tunnel\n",
    "evaluation_scenario=\"wangexp_3\"\n",
    "prior_orientation=\"fkine\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-17T17:13:54.881638Z",
     "start_time": "2023-07-17T17:13:54.880115600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# narrow_tunnel\n",
    "evaluation_scenario=\"narrow_tunnel\"\n",
    "prior_orientation=\"left\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# library 2\n",
    "evaluation_scenario=\"library2\"\n",
    "prior_orientation=\"back\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# workshop\n",
    "evaluation_scenario=\"workshop\"\n",
    "prior_orientation=\"fkine\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# wall\n",
    "evaluation_scenario=\"wall\"\n",
    "prior_orientation=\"fkine\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-17T17:13:54.884505300Z",
     "start_time": "2023-07-17T17:13:54.882989600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-17T17:13:54.888337100Z",
     "start_time": "2023-07-17T17:13:54.886825500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# get work env\n",
    "work_env = gymnasium.make(configuration[\"env_name\"], render=False, control_type=\"js\",\n",
    "                     obs_type=configuration[\"obs_type\"], goal_distance_threshold=0.05,\n",
    "                     goal_condition=goal_condition,\n",
    "                     reward_type=reward_type, limiter=configuration[\"limiter\"],\n",
    "                     show_goal_space=False, scenario=evaluation_scenario,\n",
    "                     randomize_robot_pose=False,  # if evaluation_scenario != \"wang_3\" else True,\n",
    "                     joint_obstacle_observation=\"vectors+all\",\n",
    "                     truncate_on_collision=True,\n",
    "                     terminate_on_success=True,\n",
    "                     show_debug_labels=True, n_substeps=n_substeps)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-17T17:13:55.763478800Z",
     "start_time": "2023-07-17T17:13:54.889337100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "work_env.robot.control_type = \"jsd\"\n",
    "results, metrics = evaluate.evaluate_ensemble([\"prior\"], work_env, human=human, num_episodes=100, deterministic=True,\n",
    "                                     strategy=\"\",\n",
    "                                     scenario_name=evaluation_scenario,\n",
    "                                     prior_orientation=prior_orientation)\n",
    "ee_pos = metrics[\"end_effector_positions\"]\n",
    "path_success = metrics[\"path_success\"]\n",
    "done_events  = metrics[\"done_events\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wangexp_3: 100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
     ]
    }
   ],
   "source": [
    "work_env.robot.control_type = \"js\"\n",
    "model_names = [\"gallant-serenity-299\", \"deep-frog-298\", \"solar-microwave-297\", \"revived-serenity-296\",\n",
    "                \"glamorous-resonance-295\"]\n",
    "ensemble = []\n",
    "for model_name in model_names:\n",
    "    ensemble.append(TQC.load(fr\"../run/run_data/wandb/{model_name}/files/best_model.zip\", env=work_env,\n",
    "                     custom_objects={\"action_space\": gymnasium.spaces.Box(-1.0, 1.0, shape=(7,),dtype=np.float32)}))  # for some reason it won't read action space sometimes)\n",
    "\n",
    "results, metrics = evaluate.evaluate_ensemble(ensemble, work_env, human=human, num_episodes=1, deterministic=True,\n",
    "                                     strategy=\"variance_only\",\n",
    "                                     scenario_name=evaluation_scenario,\n",
    "                                     prior_orientation=\"\")\n",
    "ee_pos = metrics[\"end_effector_positions\"]\n",
    "path_success = metrics[\"path_success\"]\n",
    "done_events  = metrics[\"done_events\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-17T17:14:00.510429800Z",
     "start_time": "2023-07-17T17:13:55.765481800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "work_env.robot.control_type = \"js\"\n",
    "model_name = \"firm-pond-79\"\n",
    "model = TQC.load(fr\"../run/run_data/wandb/{model_name}/files/best_model.zip\", env=work_env,\n",
    "                 custom_objects={\"action_space\": gymnasium.spaces.Box(-1.0, 1.0, shape=(7,),\n",
    "                                                                      dtype=np.float32)})  # for some reason it won't read action space sometimes\n",
    "\n",
    "results, metrics = evaluate.evaluate_ensemble([model], work_env, human=human, num_episodes=100, deterministic=True,\n",
    "                                     strategy=\"variance_only\",\n",
    "                                     scenario_name=evaluation_scenario,\n",
    "                                     prior_orientation=\"\")\n",
    "ee_pos = metrics[\"end_effector_positions\"]\n",
    "path_success = metrics[\"path_success\"]\n",
    "done_events  = metrics[\"done_events\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# get rendered env\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m env \u001B[38;5;241m=\u001B[39m \u001B[43mgymnasium\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfiguration\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43menv_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mrender\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontrol_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mjs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mobs_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfiguration\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mobs_type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgoal_distance_threshold\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.05\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mgoal_condition\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhalt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mreward_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreward_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfiguration\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlimiter\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mshow_goal_space\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscenario\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluation_scenario\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mrandomize_robot_pose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# if evaluation_scenario != \"wang_3\" else True,\u001B[39;49;00m\n\u001B[0;32m      9\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mjoint_obstacle_observation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mvectors+all\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mtruncate_on_collision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mterminate_on_success\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mshow_debug_labels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_substeps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_substeps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\GitHub\\panda-gym\\venv\\Lib\\site-packages\\gymnasium-0.28.1-py3.11.egg\\gymnasium\\envs\\registration.py:801\u001B[0m, in \u001B[0;36mmake\u001B[1;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001B[0m\n\u001B[0;32m    798\u001B[0m     render_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    800\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 801\u001B[0m     env \u001B[38;5;241m=\u001B[39m \u001B[43menv_creator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43menv_spec_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    802\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    803\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    804\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgot an unexpected keyword argument \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrender_mode\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    805\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m apply_human_rendering\n\u001B[0;32m    806\u001B[0m     ):\n",
      "File \u001B[1;32m~\\GitHub\\panda-gym\\panda_gym\\envs\\panda_tasks.py:124\u001B[0m, in \u001B[0;36mPandaReachAOEnv.__init__\u001B[1;34m(self, render, realtime, reward_type, goal_distance_threshold, goal_condition, control_type, obs_type, show_goal_space, scenario, randomize_robot_pose, truncate_on_collision, terminate_on_success, joint_obstacle_observation, show_debug_labels, fixed_target, limiter, action_limiter, n_substeps, collision_reward)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, render: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, realtime: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    118\u001B[0m              reward_type: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse\u001B[39m\u001B[38;5;124m\"\u001B[39m, goal_distance_threshold: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.05\u001B[39m, goal_condition\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreach\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    119\u001B[0m              control_type: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjs\u001B[39m\u001B[38;5;124m\"\u001B[39m, obs_type: \u001B[38;5;28mtuple\u001B[39m \u001B[38;5;241m=\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mee\u001B[39m\u001B[38;5;124m\"\u001B[39m,), show_goal_space\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, scenario: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcube_3_random\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    122\u001B[0m              action_limiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclip\u001B[39m\u001B[38;5;124m\"\u001B[39m, n_substeps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m20\u001B[39m, collision_reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m100\u001B[39m\n\u001B[0;32m    123\u001B[0m              ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 124\u001B[0m     sim \u001B[38;5;241m=\u001B[39m \u001B[43mPyBullet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrender\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrender\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_substeps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_substeps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    125\u001B[0m     robot \u001B[38;5;241m=\u001B[39m Panda(sim, block_gripper\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, base_position\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m0.0\u001B[39m, \u001B[38;5;241m0.0\u001B[39m, \u001B[38;5;241m0.0\u001B[39m]), control_type\u001B[38;5;241m=\u001B[39mcontrol_type,\n\u001B[0;32m    126\u001B[0m                   obs_type\u001B[38;5;241m=\u001B[39mobs_type,\n\u001B[0;32m    127\u001B[0m                   limiter\u001B[38;5;241m=\u001B[39mlimiter, action_limiter\u001B[38;5;241m=\u001B[39maction_limiter, n_substeps\u001B[38;5;241m=\u001B[39mn_substeps)\n\u001B[0;32m    128\u001B[0m     task \u001B[38;5;241m=\u001B[39m ReachAO(sim, robot, reward_type\u001B[38;5;241m=\u001B[39mreward_type, \u001B[38;5;66;03m#n_substeps=n_substeps,\u001B[39;00m\n\u001B[0;32m    129\u001B[0m                    goal_distance_threshold\u001B[38;5;241m=\u001B[39mgoal_distance_threshold,\n\u001B[0;32m    130\u001B[0m                    goal_condition\u001B[38;5;241m=\u001B[39mgoal_condition,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    139\u001B[0m                    collision_reward\u001B[38;5;241m=\u001B[39mcollision_reward\n\u001B[0;32m    140\u001B[0m                    )\n",
      "File \u001B[1;32m~\\GitHub\\panda-gym\\panda_gym\\pybullet.py:44\u001B[0m, in \u001B[0;36mPyBullet.__init__\u001B[1;34m(self, render, n_substeps, background_color)\u001B[0m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# self.dummy_collision_client = None\u001B[39;00m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# if dummy_client:\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m#     self.dummy_collision_client = bc.BulletClient(connection_mode=p.DIRECT)\u001B[39;00m\n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# self.physics_client = bc.BulletClient(connection_mode=p.DIRECT, options=options)\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# self.dummy_collision_client = bc.BulletClient(connection_mode=p.GUI)\u001B[39;00m\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mphysics_client\u001B[38;5;241m.\u001B[39mconfigureDebugVisualizer(p\u001B[38;5;241m.\u001B[39mCOV_ENABLE_GUI, \u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m---> 44\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mphysics_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfigureDebugVisualizer\u001B[49m(p\u001B[38;5;241m.\u001B[39mCOV_ENABLE_MOUSE_PICKING, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_substeps \u001B[38;5;241m=\u001B[39m n_substeps\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtimestep \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m500\u001B[39m\n",
      "File \u001B[1;32m~\\GitHub\\panda-gym\\venv\\Lib\\site-packages\\pybullet-3.2.5-py3.11-win-amd64.egg\\pybullet_utils\\bullet_client.py:46\u001B[0m, in \u001B[0;36mBulletClient.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m pybullet\u001B[38;5;241m.\u001B[39merror:\n\u001B[0;32m     44\u001B[0m       \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m---> 46\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[0;32m     47\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Inject the client id into Bullet functions.\"\"\"\u001B[39;00m\n\u001B[0;32m     48\u001B[0m   attribute \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(pybullet, name)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# get rendered env\n",
    "env = gymnasium.make(configuration[\"env_name\"],\n",
    "                     render=True, control_type=\"js\",\n",
    "                     obs_type=configuration[\"obs_type\"], goal_distance_threshold=0.05,\n",
    "                     goal_condition=\"halt\",\n",
    "                     reward_type=reward_type, limiter=configuration[\"limiter\"],\n",
    "                     show_goal_space=False, scenario=evaluation_scenario,\n",
    "                     randomize_robot_pose=False,  # if evaluation_scenario != \"wang_3\" else True,\n",
    "                     joint_obstacle_observation=\"vectors+all\",\n",
    "                     truncate_on_collision=True,\n",
    "                     terminate_on_success=True,\n",
    "                     show_debug_labels=True, n_substeps=n_substeps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-17T17:14:00.509429700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# clear env\n",
    "env.task.sim.remove_all_debug_text()\n",
    "for sphere in sphere_list:\n",
    "    env.task.sim.physics_client.removeBody(env.task.sim._bodies_idx[sphere])\n",
    "env.task.create_goal_outline() # workaround\n",
    "\n",
    "# hide goal\n",
    "env.task.sim.set_base_pose(\"target\", np.array([0.0, 0.0, -1.0]), np.array([0.0, 0.0, 0.0, 1.0]))\n",
    "# change visual shape of robot\n",
    "\n",
    "path_suc2 = path_success[:50]\n",
    "done_suc2 = np.ones(50) #metrics[\"done_events\"][100:200]\n",
    "done_normal = done_events[100:200]\n",
    "path_normal = ee_pos[100:200]\n",
    "\n",
    "for trajectory, done_event in zip(ee_pos, done_events):\n",
    "    color = 1.0\n",
    "    traj = deepcopy(trajectory)\n",
    "    final_pos = copy(traj[-1])\n",
    "    xyz1 = traj.pop()\n",
    "\n",
    "\n",
    "    while traj:\n",
    "        xyz2 = traj.pop()\n",
    "        pybullet.addUserDebugLine(lineFromXYZ=xyz1, lineToXYZ=xyz2, lineColorRGB=np.array([1-color,color,0]), physicsClientId=1, lifeTime=0, lineWidth=2)\n",
    "        color = len(traj)/len(trajectory)#1/max_ep_steps\n",
    "        xyz1 = xyz2\n",
    "\n",
    "    if done_event == 1:\n",
    "            env.task.sim.create_sphere(\n",
    "            body_name=f\"sphere{sphere_count}\",\n",
    "            radius=0.01,\n",
    "            mass=0.0,\n",
    "            ghost=True,\n",
    "            position=final_pos,\n",
    "            rgba_color=np.array([0.0, 1.0, 0.0, 1.0]),\n",
    "        )\n",
    "    elif done_event == 0:\n",
    "        env.task.sim.create_sphere(\n",
    "            body_name=f\"sphere{sphere_count}\",\n",
    "            radius=0.01,\n",
    "            mass=0.0,\n",
    "            ghost=True,\n",
    "            position=final_pos,\n",
    "            rgba_color=np.array([1.0, 1.0, 0.0, 1.0]),\n",
    "        )\n",
    "    else:\n",
    "        env.task.sim.create_sphere(\n",
    "            body_name=f\"sphere{sphere_count}\",\n",
    "            radius=0.01,\n",
    "            mass=0.0,\n",
    "            ghost=True,\n",
    "            position=final_pos,\n",
    "            rgba_color=np.array([1.0, 0.0, 0.0, 1.0]),\n",
    "        )\n",
    "    sphere_list.append(f\"sphere{sphere_count}\")\n",
    "    sphere_count += 1\n",
    "\n",
    "# plot with debug line\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "#\n",
    "# ax.plot(x, y, z, label='3D trajectory')\n",
    "# ax.legend()\n",
    "#\n",
    "# plt.show()\n",
    "winsound.Beep(2000, 1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "pybullet.changeVisualShape(objectUniqueId=0, linkIndex=1, rgbaColor=[1,1,1,0.5], physicsClientId=1)\n",
    "pybullet.changeVisualShape(objectUniqueId=0, linkIndex=3, rgbaColor=[1,1,1,1], physicsClientId=1)\n",
    "# pybullet.changeVisualShape(objectUniqueId=0, linkIndex=2, rgbaColor=[1,1,1,0.5])\n",
    "# pybullet.changeVisualShape(objectUniqueId=0, linkIndex=1, rgbaColor=[1,1,1,0.5])\n",
    "# pybullet.changeVisualShape(objectUniqueId=0, linkIndex=0, rgbaColor=[1,1,1,0.5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "env.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
